<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on GOV 1347: Election Analytics Blog</title>
    <link>http://localhost:4321/election-blog/post/</link>
    <description>Recent content in Posts on GOV 1347: Election Analytics Blog</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:4321/election-blog/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Forecast 10/21/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/10/18/week-7-forecast/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/10/18/week-7-forecast/</guid>
      <description>&lt;link href=&#34;http://localhost:4321/election-blog/election-blog/post/2024/10/18/week-7-forecast/index_files/pagedtable/css/pagedtable.css&#34; rel=&#34;stylesheet&#34; /&gt;&#xA;&lt;script src=&#34;http://localhost:4321/election-blog/election-blog/post/2024/10/18/week-7-forecast/index_files/pagedtable/js/pagedtable.js&#34;&gt;&lt;/script&gt;&#xA;&lt;h1&gt;Week 6: October 21, 2024&lt;/h1&gt;  &#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election.&#xA;&lt;h2&gt;Context &amp; Question&lt;/h2&gt;&#xA;In this week&#39;s post, I focus on the application of Bayesian Models in election prediction. Bayesian statistics is based on the notion that the probability of an event occurring can be modeled as some function with some unknown parameter(s). When we first look at some event, our parameter value will be based on our *prior* beliefs regarding the process or event. But as we collect *data*, we update the parameter(s) to improve our predictions about whether the event will occur. Bayesian statistics stands in contrast to Frequentist statistics. Frequentists predict the probability of an event based on how many ties it&#39;s happened in the past (in a dataset, for example). They believe that a paramter has a fixed value and rather than updating it based on data, frequentists are prone to quantifying the *likelihood* that a parameter is equal to some given value, based on data.  &#xA;Bayesian models can be powerful in election analytics because datasets constantly change, and audiences/statisticians can update their understandings of probable outcomes based on them. Datasets can change as a result of updated polls, OR as election returns are collected during periods of Early/Mail-in Voting, which have grown in popularity over the past several years. In my model, I propose using both: I will ground my prior parameters in poll results (calling back to some elements of my post from September 21st) and update them conditional on early voting returns.   &#xA;&lt;h2&gt;The Data&lt;/h2&gt;&#xA;The polling data in this week&#39;s post is broken down by state. Since I&#39;m using the same data from my September 21st post, the latest polling average that I use for my prior probability is from September 16th, 2024. The early voting returns were obtained from the [Associated Press](https://apnews.com/hub/election-2024) and contain returns by party for all states that have started early voting. It&#39;s important to note that not all states have made early voting available yet, so only 40 states&#39; returns are represented in this dataset.&#xA;&lt;h2&gt;Building the Model&lt;/h2&gt;&#xA;Let our prior belief about each candidate&#39;s performance in the election be represented by their last polling average. If we took polling averages from September 16th, 2024 to represent the election outcome, the electoral map would look like the following.&#xA;&lt;p&gt;It&amp;rsquo;s worth noting that this dataset only contained polls for 15 states. Granted, many of them are swing states (i.e. Pennsylvania, Georgia, Michigan, and North Carolina), but our prediction and model would be more complete with access to data from all 50 states.&lt;br&gt;&#xA;Next, I use visualize the election outcome based only on states for which early voting returns are available.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Forecast 10/14/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/10/10/week-6-forecast/</link>
      <pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/10/10/week-6-forecast/</guid>
      <description>&lt;h1&gt;Week 6: October 14, 2024&lt;/h1&gt;  &#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election.&#xA;&lt;h2&gt;Context &amp; Question&lt;/h2&gt;&#xA;The focus of this week&#39;s post is campaign advertising. I decided to do a callback to the post from September 30th and investigate the difference between incumbent candidates and challenger candidates when it comes to advertising. Do ad tones change for incumbent candidates and challengers? Are the tones of advertisements markedly different for successful candidates versus unsuccessful ones?&#xA;&lt;h2&gt;Exploratory Analysis&lt;/h2&gt;&#xA;Before I investigate the relationships between ad tone and incumbency, I want to expose some of the trends in campaign ads since the 2000 election.&#xA;&lt;p&gt;First we can get an idea of &lt;em&gt;why&lt;/em&gt; campaigns run ads. The following plot shows the distributions of campaign motives for Democratic and Republican candidates in the elections between 200 and 2016. Candidates could run &amp;ldquo;personal,&amp;rdquo; versus &amp;ldquo;policy,&amp;rdquo; versus &amp;ldquo;other&amp;rdquo; ads. Both parties&amp;rsquo; candidates &lt;em&gt;tended&lt;/em&gt; to air ads that focused on policy, a trend that was broken in 2016 when candidate Donald Trump devoted a significant majority of his advertising to personal issues/causes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Forecast 10/07/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/10/04/week-5-forecast/</link>
      <pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/10/04/week-5-forecast/</guid>
      <description>&lt;h1&gt;Week 5: October 7, 2024&lt;/h1&gt;  &#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election.&#xA;&lt;h2&gt;Context &amp; Question&lt;/h2&gt;&#xA;A [study analyzing errors in 2016 election polling](https://digitalcommons.unl.edu/sociologyfacpub/543/) found that most pollsters overweighted the responses of people who didn&#39;t actually cast a ballot on election day. They may have weighted all responses equally, failing to account for people&#39;s likelihoods to vote, or they could have weighted responses based on a factor not-related or inversely related to voter turnout. But how would a pollster know if a surveyed subject was &#34;likely to vote.&#34; According to the researchers, those most likely to vote were people who owned landline phones!  &#xA;I&#39;m skeptical that the sheer act of having a wall/landline phone in one&#39;s home, and walking over to it every time they receive a call makes them likely to vote... but it&#39;s possible that there are *other demographic features* of people with landline phones that *also and independently* influence their decision to cast a ballot. These could include age, race, type of residence/neighborhood, and those are exactly the factors that I&#39;ll analyze in this week&#39;s post!  &#xA;In this post I build a model for predicting the national democratic vote share by creating three likelihoods that people will turnout to vote, based on race, age, and education level, respectively. I code these variables into 4 categories, and one limitation is the 64 distinct combinations of identities that people can possess. It&#39;s impossible to predict turnout at the *individual level* from this data, because different voters may be swayed based on *different* elements of their identify (i.e. while one voter may strongly identify and vote alongside people of the same race, another voter may be more encouraged by voters their own age.)&#xA;&lt;h2&gt;The Data&lt;/h2&gt;&#xA;I cleaned datasets for voter age, race, education level, turnout rate, and share of the electorate for all general and midterm elections since 1986. The charts below summarize turnout rate for each category over time:&#xA;&lt;pre&gt;&lt;code&gt;## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──&#xA;## ✔ dplyr     1.1.3     ✔ readr     2.1.5&#xA;## ✔ forcats   1.0.0     ✔ stringr   1.5.0&#xA;## ✔ ggplot2   3.4.4     ✔ tibble    3.2.1&#xA;## ✔ lubridate 1.9.3     ✔ tidyr     1.3.0&#xA;## ✔ purrr     1.0.2     &#xA;## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──&#xA;## ✖ dplyr::filter() masks stats::filter()&#xA;## ✖ dplyr::lag()    masks stats::lag()&#xA;## ℹ Use the conflicted package (&amp;lt;http://conflicted.r-lib.org/&amp;gt;) to force all conflicts to become errors&#xA;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Forecast 09/30/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/09/29/week-4-forecast/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/09/29/week-4-forecast/</guid>
      <description>&lt;h1&gt;Week 4: September 30, 2024&lt;/h1&gt;  &#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election.&#xA;&lt;h2&gt;Context &amp; Question&lt;/h2&gt;&#xA;In the 18 elections since the end of World War II (1948), incumbent candidates have won a third of them. But considering that the incumbent president has only run in 11 of those elections, the statistic comes out to be that the incumbent won in about **two-thirds** of elections in which they were running. So this week&#39;s blog explores whether incumbency really matters in a presidential race, and whether it&#39;s a good prediction of an election outcome. We can measure &#34;incumbency&#34; both on the basis of the candidate and the party. This is especially interesting in the 2024 race because one candidate (Donald Trump) is not a *direct* incumbent, meaning he did not serve in the pevious term, but he has served before. And the other candidate (Kamala Harris) is a member of the incumbent party *and* incumbent administration, but is not a president seeking re-election.&#xA;&lt;h2&gt;The Data&lt;/h2&gt;&#xA;I&#39;ll use data about the popular vote in each state since 1948 to determine whether incumbents performed consistently well or poorly in certain states over time, or whether their performance in different states was subject to the volatility in states (i.e. is incumbent performance consistent even in states considered &#34;battleground&#34; between parties?)&#xA;&lt;h2&gt;Results&lt;/h2&gt;&#xA;&lt;p&gt;First, I decided to investigate whether particular states tend to vote for incumbent parties more often than others. The maps below show each state that voted for an incumbent party versus a challenger party&amp;rsquo;s candidate in every election since 1948.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Forecast 09/21/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/09/21/week-3-forecast/</link>
      <pubDate>Sat, 21 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/09/21/week-3-forecast/</guid>
      <description>&lt;h1&gt;Week 3: September 23, 2024&lt;/h1&gt;  &#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election.&#xA;&lt;h2&gt;Context &amp; Question&lt;/h2&gt;&#xA;Since the 19th century, polls have been conducted to predict the outcomes of U.S. presidential elections. While they ultimately predict a binary outcome (i.e. will candidate A win or lose the election), they usually convey their results in percentages (i.e. what percent of the vote can candidate A expect to receive, what percent chance does candidate A have of victory). Polls do this at both the national level and the state level. The results are publicly disseminated, usually in newspapers. in addition to informing the electorate, they may influence voter behavior or motivation. This post asks whether polls (national or state) that show two candidates close to each other correspond to higher turnout rates and vice versa: whether polls that show one candidate defeating the other by a high margin actually discourage turnout (with voters reasoning that their opinion will not shift the result). If polls do cause turnout rates to change, they may also cause the results they&#39;re predicting to flesh out differently (if not every individual polled shows up to vote, then the results they contributed to forecasting will likely vary in reality).  &#xA;In this week&#39;s blog post, I analyze a set of presidential polling averages by state from 1968 through 2024 to (1) evaluate whether close polls are associated with higher or lower voter turnout and (2) evaluate whether polls that forecast close races should adjust for turnout in one direction, and polls that forecast landslide results the other. Recognizing that &#34;should&#34; is subjective, I use it to evaluate whether the poll would be more accurate compared to the actual result if adjusted for turnout (high or low).&#xA;&lt;h2&gt;The Data&lt;/h2&gt;&#xA;In this post, I convey polling averages in three datasets. The first contains candidates&#39; polling averages from 1968-2016, the second contains the data from 2020, and the third contains the data from 2024. Each dataset is structured the same. They each contain a mix of nation-wide and state-wide polls and provide a percentage estimate for how much of the vote, in the nation or in the specified state, a candidate will receive. the particular candidate is named in a separate column. There is also a column in which the vote-share estimate is adjusted for national trends, but I choose to focus on the regular, raw percent estimates in this analysis.&#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# load data--polling averages&#xA;avg_68_16 &amp;lt;- read.csv(&amp;quot;pres_pollaverages_1968-2016.csv&amp;quot;)&#xA;avg_20 &amp;lt;- read.csv(&amp;quot;pres_pollaverages_2020.csv&amp;quot;)&#xA;avg_24 &amp;lt;- read.csv(&amp;quot;pres_pollaverages_2024.csv&amp;quot;)&#xA;&lt;/code&gt;&lt;/pr</description>
    </item>
    <item>
      <title>Forecast 09/16/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/09/16/week-2-forecast/</link>
      <pubDate>Mon, 16 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/09/16/week-2-forecast/</guid>
      <description>&lt;h1&gt;Week 2: September 16, 2024&lt;/h1&gt;  &#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election.&#xA;&lt;h2&gt;Context &amp; Question&lt;/h2&gt;&#xA;In his successful 1992 campaign for the U.S. Presidency, Bill Clinton is quoted as saying &#34;it&#39;s the economy, stupid.&#34; Clinton implied that, in a strong economy, voters would favor an incumbent candidate/party, and vice versa in a weak economy. There are several philosophies about what constitutes a &#34;strong economy.&#34; Changes in GDP, in GDP per capita, unemployment rate, and inflation rate are all indicators. In this post, I&#39;m interested in looking at the strength of the U.S. Dollar (USD) relative to the currencies of major trading partners and allies, and seeing if it holds predictive power in presidential elections.  &#xA;&lt;h2&gt;The Data&lt;/h2&gt;&#xA;The Federal Reserve Bank of St. Louis publishes the daily exchange rates between the U.S. dollar and a variety of other currencies. I chose to use data about the Japanese Yen, the Chinese Yuan Renminbi, the British Pound, and the Euro. The span of data available for each currency is summarized below:&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th style=&#34;text-align: left&#34;&gt;Currency&lt;/th&gt;&#xA;          &lt;th style=&#34;text-align: center&#34;&gt;Start of Data&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Japanese Yen&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;January 4, 1971&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;British Pound&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;January 4, 1971&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Chinese Yuan&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;January 2, 1981&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td style=&#34;text-align: left&#34;&gt;Euro&lt;/td&gt;&#xA;          &lt;td style=&#34;text-align: center&#34;&gt;January 4, 1999&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;The American Economy is linked to the Japanese Yen through carry-trading. The Yen has historically had no interest rate, making it an attractive currency for investors to buy, place in stocks or bonds, and then exchange for USD (or another foreign currency) before collecting the returns on their investments. However, changes in the value of the Yen can send the U.S. stock market into turmoil, as happened in the first week of August, 2024. Another reason to use the Yen is the mutual defense agreement between the U.S. and Japan. Though remnant of the post-World War II era, part of this agreement&amp;rsquo;s appeal is that the U.S. earns a profit selling defense technology to Japan. In doing so, it bolsters the nation&amp;rsquo;s capacity to defend itself and reduces the chance that the U.S. will have to intervene. In this sense fluctuations in the Yen can be foreboding about the U.S. economy. A weak Yen may cost the U.S. in defense exports, and simultaneously make U.S. intervention in Japan seem more likely, especially in the face of rising tensions between China and Taiwan, and the North Korean threat in southeast Asia.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Forecast 09/09/2024</title>
      <link>http://localhost:4321/election-blog/post/2024/09/09/forecast-09-09-2024/</link>
      <pubDate>Mon, 09 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:4321/election-blog/post/2024/09/09/forecast-09-09-2024/</guid>
      <description>&lt;h1&gt;Week 1: September 9, 2024&lt;/h1&gt;&#xA;This blog is an ongoing project for Professor Ryan Enos&#39; Election Analytics Course at Harvard College (GOV 1347, Fall 2024). It will be updated weekly with posts analyzing how different features impact the likelihood of Kamala Harris (D) or Donald Trump (R) winning the 2024 U.S. Presidential Election or winning specific states in the election. The blog will culminate in a final predictive model for the outcome of the general election. Some posts, such as this one, will examine the state of existing polls and try to explain variation between them.&#xA;&lt;h2&gt;Question&lt;/h2&gt;&#xA;While keeping up with predictions for the upcoming presidential election and making my own, I find myself float towards newspapers and media outlets. I consider myself an avid consumer of journalism, and find newspapers reliable for updated polling information. But I know that this is not true of all individuals in the electorate. In this post, I wonder if events that make headlines matter as much to voters as they do to polling agencies. That is, are pollsters are justified when they survey the electorate after a major event, or do the events reported on impact the views of their populations less than it impacted their thoguht processes. I&#39;d imagine that polls sponsored by news organizations tend to undergo updates after *those same* news organizations publish major stories, so I&#39;d like to see if sponsored polls yield similar results to each other.&#xA;&lt;h2&gt;The Data&lt;/h2&gt;&#xA;The New York Times&#39; 2024 Election Poll Tracker is updated daily with predictions for candidate performance based on aggregate results from of nation-wide and state-specific surveys. The surveys it uses are collected and displayed in a table on the poll tracker&#39;s website. I scraped these surveys from the Times&#39; website into a JSON file with fields such as the pollster&#39;s name, whether the poll had any sponsorship, and the poll&#39;s results. Then I wrote a simple Python script to convert the JSON file into a CSV format (election-blog/jsontocsv.py) Then I looked for differences in the estimates of polls sponsored by external agencies/organizations versus those not sponsored at all. In a future analysis, I hope to compare polls sponsored by news outlets to polls sponsored by other organizations (e.g. colleges, universities), but due to the limited sample size (The New York Times only provided 50 polls because it did not include any polls that began earlier than August 6, 2024. Only 17 of them were sponsored at all) I chose to compare polls sponsored by *any* entity to those run by independent pollsters in this post.&#xA;&lt;h2&gt;Methods/Analyses&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code class=&#34;language-r&#34;&gt;# install packages&#xA;library(ggplot2)&#xA;library(maps)&#xA;library(tidyverse)&#xA;&lt;/code&gt;&lt;/pr</description>
    </item>
  </channel>
</rss>
